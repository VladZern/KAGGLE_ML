EDA (exploratory data analysis). - подходы к визуализации данных (статистики по датасету, боксплоты, разброс категорий, ...)

Data Cleaning — все, что касается очистки данных. Выбросы, пропуски, и т.д. (пропуски через fillna, чистка категорий, объединение категорий)

Data preparation — все, что касается подготовки данных для модели. Несколько блоков: 
                                                                                     *Общий (обработка категорий — label/ohe/frequency,                                                                                       проекция числовых на категории, трансформация числовых,                                                                                                                  бининг)
                                                                                     *Для регрессий/нейронных сетей (различное                                                                                                               масштабирование)
                                                                                     *Для деревьев
                                                                                     *Специальный (временные ряды, картинки, FM/FFM)
                                                                                     *Текст (Vectorizers, TF-IDF, Embeddings)
Models:
        Linear models (различные регрессии — ridge/logistic)
        Tree models   (lgb)
        Neural Networks
        Exotic (FM/FFM)

Feature selection (grid/random search)

Hyperparameters search

Ensemble (Regression / lgb)

Алгоритм:
    1) Прогоняем данные через наш сформированный пайплайн и сабмитим результат
    2) Читаем все кернелы на предмет использованных техник и подходов
    3) Читаем все обсуждения на форуме
    4) Переделываем/дополняем пайплайны новыми техниками

Что вы делаете дальше:
       Ждете пять дней. Не читайте форум, забудьте про Kaggle на это время. Дайте мозгу отдохнуть и размылить взгляд.
       Возвращаетесь к соревнованию. За эти пять дней по правилам хорошего тона все топы выложат описание своих решений — в постах на      
       форуме, в виде кернелов, в виде гитхабовских репозиториев.

       Вы берете несколько листов формата А4, на каждом пишете название модуля из вышеописанного фреймворка (EDA/ Preparation/ Model/ 
       Ensemble/ Feature selection/ Hyperparameters search/ ...)
       Последовательно читаете все решения, выписываете на соответствующие листочки новые для вас техники, методы, подходы.

       Последовательно по каждому модулю пишете (подсматриваете) реализацию этих подходов и методов, расширяя ваш пайплайн и библиотеки.
       В режиме пост-сабмита прогоняете данные через ваш обновленный пайплайн до тех пор, пока у вас не будет решения в золотую зону.
       

Что примерно должно быть в пайплайнах к концу данного этапа:

Всевозможные варианты предобработки и создания числовых фичей — проекции, отношения,
Различные методы работы с категориями — Mean target encoding в правильном варианте, частоты, label / ohe,
Различные схемы ембеддингов над текстом (Glove, Word2Vec, Fasttext)
Различные схемы векторизации текста (Count, TF-IDF, Hash)
Несколько валидационных схем (N*M для стандартной кросс-валидации, time-based, by group)
Bayesian optimization / hyperopt / что-то еще для подбора гиперпараметров
Shuffle / Target permutation / Boruta / RFE — для отбора фич
Линейные модели — в едином стиле над одним набором данных
LGB/XGB/Catboost — в едином стиле над одним набором данных
Несколько нейронных сетей на все случаи жизни (не берем пока картинки) — embeddings/CNN/RNN для текста, RNN для последовательностей, Feed-Forward для всего остального. Хорошо еще понимать и уметь автоенкодеры.
Ансамбль на базе lgb/regression/scipy — для задач регрессии и классификации
Хорошо еще уже уметь Genetic Algorithms, иногда они хорошо заходят

План работы над проектом:
1) Осознание задачи 
  а) Загрузка библиотек 
  б) Загрузка набора данных
  в) Описательная статистика 
  г) Визуализация данных

2) Подготовка данных 
   a) Очистка данных, обработка нулевых значений
   b) Выбор признаков 
   c) Преобразование признаков (нормализация, кодирование)

3) Алгоритмы оценки 
  a) Кросс валидация
  b) Метрика оценки 
  c) Сравнение алгоритмов

4) Повышение точности 
   а) Настройка Алгоритма 
   б) Ансамбли

5) Завершение модели 
   a) Предсказания для набора данных
   b) Создание автономной модели для всего набора данных обучения 
   c) Сохранение модели для последующего использования

